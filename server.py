import io
import os
import sys
import asyncio
import traceback
import torch
import numpy as np
import soundfile as sf
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional

# =======================================================
# 1. é…ç½®ä¸åˆå§‹åŒ–
# =======================================================
app = FastAPI(title="Chatterbox Server (Dynamic Voice)")
gpu_lock = asyncio.Lock()

print("â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

chat = None

# åŠ è½½æ¨¡å‹
try:
    from chatterbox import ChatterboxTTS
    print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹ (from_pretrained)...")
    chat = ChatterboxTTS.from_pretrained(device=device)
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ ChatterboxTTS")
    sys.exit(1)

# å¯»æ‰¾æ ¸å¿ƒæ–¹æ³•
if not hasattr(chat, 'prepare_conditionals') or not hasattr(chat, 'generate'):
    print("âŒ è‡´å‘½é”™è¯¯ï¼šæ­¤ç‰ˆæœ¬çš„ Chatterbox ä¸æ”¯æŒ prepare_conditionals/generate æµç¨‹")
    sys.exit(1)

# =======================================================
# 2. åå°ä»»åŠ¡ (æ”¯æŒåŠ¨æ€éŸ³è‰²è·¯å¾„)
# =======================================================
def _sync_inference_task(text, voice_path, seed, output_format):
    """
    è¿è¡Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­çš„æ¨ç†ä»»åŠ¡
    """
    # 1. æ£€æŸ¥éŸ³è‰²æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(voice_path):
        raise FileNotFoundError(f"æœåŠ¡ç«¯æœªæ‰¾åˆ°éŸ³è‰²æ–‡ä»¶: {voice_path}")

    if seed:
        torch.manual_seed(int(seed))
        np.random.seed(int(seed))
        
    try:
        # 2. å‡†å¤‡éŸ³è‰²æ¡ä»¶ (è¯»å–æŒ‡å®šçš„ voice_path)
        # Faståˆ†æ”¯é€»è¾‘: prepare_conditionals(wav_fpath=...)
        conds = chat.prepare_conditionals(wav_fpath=voice_path)
        
        # 3. ç”ŸæˆéŸ³é¢‘
        try:
            # å°è¯•æ ‡å‡†è°ƒç”¨: generate(text, conds)
            wavs = chat.generate(text, conds)
        except TypeError:
            try:
                wavs = chat.generate([text], conds)
            except TypeError:
                wavs = chat.generate(text=text, conditionals=conds)

        # 4. åå¤„ç†
        if isinstance(wavs, tuple): wavs = wavs[0]
        if isinstance(wavs, list) and len(wavs) > 0: wavs = wavs[0]
        if isinstance(wavs, torch.Tensor): wavs = wavs.cpu().numpy()
        
        audio_data = np.array(wavs).flatten()
        
        # 5. å¯¼å‡º
        buffer = io.BytesIO()
        fmt = "WAV" if output_format.lower() == "wav" else "MP3"
        sf.write(buffer, audio_data, 24000, format=fmt)
        buffer.seek(0)
        return buffer, fmt

    except Exception as e:
        print(f"âŒ æ¨ç†é”™è¯¯: {e}")
        traceback.print_exc()
        raise e

# =======================================================
# 3. API æ¥å£
# =======================================================
class TTSRequest(BaseModel):
    text: str
    voice_path: str = "voices/Jordan.wav" # é»˜è®¤å€¼ï¼Œå®¢æˆ·ç«¯å¯ä»¥è¦†ç›–
    seed: Optional[int] = None
    output_format: str = "mp3"

@app.post("/tts")
async def tts_endpoint(req: TTSRequest):
    async with gpu_lock:
        loop = asyncio.get_running_loop()
        try:
            buffer, fmt = await loop.run_in_executor(
                None, 
                _sync_inference_task, 
                req.text, req.voice_path, req.seed, req.output_format
            )
            media_type = "audio/wav" if fmt == "WAV" else "audio/mpeg"
            return StreamingResponse(buffer, media_type=media_type)
        except FileNotFoundError as e:
            raise HTTPException(404, str(e))
        except Exception as e:
            raise HTTPException(500, f"Generation Error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    # ä¾ç„¶æ¨èå¤š worker
    uvicorn.run(app, host="0.0.0.0", port=8004)
